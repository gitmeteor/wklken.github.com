<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>wklken's blog - system</title><link>http://www.wklken.me/</link><description></description><lastBuildDate>Wed, 29 Jun 2016 00:00:00 +0800</lastBuildDate><item><title>ElasticSearch集群部署文档</title><link>http://www.wklken.me/posts/2016/06/29/deploy-es.html</link><description>&lt;p&gt;官方es搭建步骤写的很简略, 但是实际搭建过程中, 会涉及一系列环境配置. 以下的流程, 是在搭建过程中梳理出来的详细步骤(实践过3遍以上)&lt;/p&gt;
&lt;p&gt;其实, 这些流程在具体应用的时候, 都可以变成自动化脚本, 或者直接用docker好了, 以便扩容足够快(目前我们用的打包成集成安装包, 实现脚本自动部署)&lt;/p&gt;
&lt;p&gt;只是简单集群的基本设置, 不涉及调优的参数配置, 不涉及&lt;code&gt;client/master/data&lt;/code&gt;节点区分等等. 可以参照搭建的主体流程.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="ban-ben-ji-lian-jie"&gt;版本及连接&lt;/h2&gt;
&lt;p&gt;elasticseearch版本: 2.3.3&lt;/p&gt;
&lt;p&gt;相关链接:
- &lt;a href="https://www.elastic.co/products/elasticsearch"&gt;官网&lt;/a&gt;
- &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html"&gt;文档&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="xi-tong-yao-qiu"&gt;系统要求&lt;/h2&gt;
&lt;p&gt;如果仅作测试用, 不需要两天机器, 可以将两个节点部署在同一台机器上, 对磁盘/cpu要求不高, 内存大于2g基本足够了&lt;/p&gt;
&lt;p&gt;如果是正式环境, 需要根据日志量进行评估, 例如, 每天日志量占硬盘约约10G, 且保留30天日志, 则磁盘会占用约300g, es设定的阈值是磁盘空间占满85%则日志开始告警. 所以, 需要至少 &lt;code&gt;300/0.85=354g …&lt;/code&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Wed, 29 Jun 2016 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.wklken.me,2016-06-29:/posts/2016/06/29/deploy-es.html</guid><category>system</category></item><item><title>Logstash+ElasticSearch处理mysql慢查询日志</title><link>http://www.wklken.me/posts/2016/05/24/elk-mysql-slolog.html</link><description>&lt;p&gt;遇到一个需求, 需要查询某些业务的慢查询日志. 结果DBA平台那边提供的慢查询日志不能解决实际的业务场景(上报的字段补全), 无奈, 自己挽起袖子上&lt;/p&gt;
&lt;p&gt;参考了 &lt;a href="https://www.phase2technology.com/blog/adding-mysql-slow-query-logs-to-logstash/"&gt;这篇文章&lt;/a&gt;, 不过自己根据需求做了较多的变更&lt;/p&gt;
&lt;p&gt;开始吧&lt;/p&gt;
&lt;h2 id="1-zhao-dao-ri-zhi-de-wei-zhi"&gt;1. 找到日志的位置&lt;/h2&gt;
&lt;p&gt;先确认是否开启了, 然后找到日志文件的位置&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt; show variables like '%slow%';
+---------------------+-------------------------------------+
| Variable_name       | Value                               |
+---------------------+-------------------------------------+
| log_slow_queries    | ON                                  |
| slow_launch_time    | 2                                   |
| slow_query_log      | ON                                  |
| slow_query_log_file | /data/mysqllog/20000/slow-query.log |
+---------------------+-------------------------------------+
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="2-man-cha-xun-ri-zhi"&gt;2. 慢查询日志&lt;/h2&gt;
&lt;p&gt;格式基本是如下, 当然, 格式如果有差异, 需要根据具体格式进行小的修改&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# Time: 160524  5:12:29
# User@Host: user_a[xxxx] @  [10.166.140 …&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Tue, 24 May 2016 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.wklken.me,2016-05-24:/posts/2016/05/24/elk-mysql-slolog.html</guid><category>system</category></item><item><title>ELK维护的一些点(二)</title><link>http://www.wklken.me/posts/2016/05/07/elk-about-2.html</link><description>&lt;p&gt;很杂, 涉及到最近处理的一些点&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="gen-ju-stringzhuan-fu-dian-shu-de-mou-ge-zi-duan-pai-xu"&gt;根据string转浮点数的某个字段排序&lt;/h3&gt;
&lt;p&gt;一个字段, &lt;code&gt;resp_time&lt;/code&gt;, mapping中是string, 有需求是, 按照响应时间降序排序, 此时需要构造qsl(在search中使用), 使用该字段转换为浮点数, 降序排列&lt;/p&gt;
&lt;p&gt;第一步, 修改es配置, 增加groovy支持&lt;/p&gt;
&lt;p&gt;elasticsearch.yml中加入&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;script.engine.groovy.inline.search: on
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后, 执行 &lt;a href="http://www.wklken.me/posts/2016/02/16/elk-about-upgrade.html#rolling-restart"&gt;rolling restart&lt;/a&gt;, 逐一重启集群每个节点&lt;/p&gt;
&lt;p&gt;第二步, 构造qsl,  &lt;code&gt;sort&lt;/code&gt;中,  增加&lt;code&gt;_script&lt;/code&gt; 使用groovy脚本, 将对应字段从string转成数字, 再进行排序&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;'sort': [{'_script': {'lang': 'groovy',
                       'order': 'desc',
                       'script': 'Float.parseFloat(doc["resp_time"].value)',
                       'type' …&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Sat, 07 May 2016 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.wklken.me,2016-05-07:/posts/2016/05/07/elk-about-2.html</guid><category>system</category></item><item><title>ELK 维护的一些点</title><link>http://www.wklken.me/posts/2016/02/16/elk-about-upgrade.html</link><description>&lt;p&gt;去年入职新公司之后, 负责维护平台的elk&lt;/p&gt;
&lt;p&gt;这套东西是2013年搭建的, 年久失修, 所以做了个方案, 开始了批量升级&lt;/p&gt;
&lt;p&gt;将logstash从1.3升级到2.1, 将elasticsearch从1.4.1升级到2.0&lt;/p&gt;
&lt;p&gt;期间踩了很多坑, 搞了一个多月, 总算搞完&lt;/p&gt;
&lt;p&gt;从纯手工落后隔三差五有人找查问题的自行车, 改成自动化最新版本新架构运维便捷上了两个月无人反馈的, 额, 小汽车:) - 集成安装包/shell脚本/fabric实现部署/升级/增删/加黑名单等等功能&lt;/p&gt;
&lt;p&gt;每天日志量大概10G上下, 几十个采集端, 两个redis, 两个indexer, 两台es机器扛起&lt;/p&gt;
&lt;p&gt;以下, 不那么严谨地, 记录一些遇到的问题&lt;/p&gt;
&lt;h4 id="1-logstashsheng-ji-ce-lue"&gt;1. logstash升级策略&lt;/h4&gt;
&lt;p&gt;logstash1.3到2.x, 变化点还是很多的&lt;/p&gt;
&lt;p&gt;所以, 首先第一步要去阅读官方文档, 将所有change log过一遍, 对一些关键性的东西进行了解, 比如, 干掉了哪些语法(旧的功能需要如何实现), 哪些语法有变更, 新增了哪些特性等 …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Tue, 16 Feb 2016 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.wklken.me,2016-02-16:/posts/2016/02/16/elk-about-upgrade.html</guid><category>system</category></item><item><title>Logstash+ElasticSearch+Kibana处理nginx访问日志</title><link>http://www.wklken.me/posts/2015/04/26/elk-for-nginx-log.html</link><description>&lt;p&gt;&lt;code&gt;ELK&lt;/code&gt;似乎是当前最为流行的日志收集-存储-分析的全套解决方案.&lt;/p&gt;
&lt;p&gt;去年年初, 公司里已经在用, 当时自己还&lt;code&gt;山寨&lt;/code&gt;了一个统计系统(postgresql-echarts, 日志无结构化, json形式存储到postgresql, 构建统一前端配置生成, 调用统一查询接口, &lt;a href="http://www.wklken.me/posts/2014/11/16/unit-statistics-system.html"&gt;具体细节&lt;/a&gt;), 已经过了一年有余.&lt;/p&gt;
&lt;p&gt;一年刚好, 发生了很多事, 那套系统不知现在如何了.&lt;/p&gt;
&lt;p&gt;在新的公司, 一切都得从0到1, 近期开始关注日志/数据上报/统计, 以及后续的数据挖掘等.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;搭建, 测试并上线了一套简单的系统, 初期将所有服务器的nginx日志, 以及搜索日志进行处理.&lt;/p&gt;
&lt;p&gt;&lt;img alt="elk" src="/imgs/system/elk.png"/&gt;&lt;/p&gt;
&lt;p&gt;下面主要介绍对nginx日志进行处理的过程, 不是针对&lt;code&gt;elk&lt;/code&gt;的介绍, 所有涉及ip的地方都改成&lt;code&gt;127.0.0.1&lt;/code&gt;了, 根据自己环境进行修改&lt;/p&gt;
&lt;h3 id="1-nginxri-zhi-logstash-shipper-redis"&gt;1. nginx日志 -&amp;gt; logstash shipper -&amp;gt; redis&lt;/h3&gt;
&lt;p&gt;在&lt;code&gt;centos&lt;/code&gt;使用&lt;code&gt;yum&lt;/code&gt;安装&lt;code&gt;nginx&lt;/code&gt;后 …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Sun, 26 Apr 2015 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.wklken.me,2015-04-26:/posts/2015/04/26/elk-for-nginx-log.html</guid><category>system</category></item><item><title>基于 PostgreSQL 的数据统计系统</title><link>http://www.wklken.me/posts/2014/11/16/unit-statistics-system.html</link><description>&lt;p&gt;看到标题就知道我要写什么了, 这是之前一个项目的小结吧, 自己对统计的一些认识和看法.&lt;/p&gt;
&lt;p&gt;当时从前到后, 包括技术选型, 花了接近一个月的时间, 也在生产上用了两三个月, 一致在持续维护, 做完图表配置化已然接近完工, 无奈后来离开了, 不过目前应该还在运转&lt;/p&gt;
&lt;p&gt;至于源代码, 暂时不考虑开源, 太渣(其中在看了几天js情况下, 自己撸了1000行js的前端框架, 质量堪忧), 全套用python实现.&lt;/p&gt;
&lt;p&gt;提供一种快速实现运营统计需求的思路.&lt;/p&gt;
&lt;p&gt;(图为百度 echarts 示例)&lt;/p&gt;
&lt;p&gt;&lt;img alt="statistics" src="/imgs/system/statistics.png"/&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="yi-chang-jing"&gt;一. 场景&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;统计&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所谓统计, 抽象出来就是计数而已(还有各个计数之间的算术运算). 再具体一些, 根据不同维度进行计数.&lt;/p&gt;
&lt;p&gt;而统计后台, 无外乎数据的输入, 处理, 及输出.&lt;/p&gt;
&lt;p&gt;对于实时性, 一般会以天为单位进行统计.&lt;/p&gt;
&lt;p&gt;而在具体业务场景下, 需要计数的数据来源于各个项目和同一个项目的不同机器(分布式部署), 就需要考虑, 如何将日志进行汇聚, 如何更为便捷地进行处理, 存储, 以及展现.&lt;/p&gt;
&lt;p&gt;其中要考虑, 需求是不断在变化的, 如何将成本降到最低?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以往的统计方式:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;分析统计需求 -&amp;gt; 修改项目记录日志内容和格式 …&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Sun, 16 Nov 2014 20:58:00 +0800</pubDate><guid isPermaLink="false">tag:www.wklken.me,2014-11-16:/posts/2014/11/16/unit-statistics-system.html</guid><category>system</category></item><item><title>简单搜索系统组成总结</title><link>http://www.wklken.me/posts/2014/06/09/search-system.html</link><description>&lt;p&gt;最近在进行离职前交接工作了, 对之前做的一些东西也大概进行了下简单总结.&lt;/p&gt;
&lt;p&gt;今天整理了下, 搜索系统组成简要描述, 一些思想, 不涉及太多具体实现.&lt;/p&gt;
&lt;p&gt;这套系统从开始设计到最终完成, 前前后后花了3个月的样子(计算所有时间投入), 也算是做得感觉比较完善的一套系统.&lt;/p&gt;
&lt;p&gt;上线接近一年, 支持快玩游戏搜索业务(快玩盒子/快玩网站/移动端等), 系统每天百万级的搜索(峰值在250w左右, 应用层两台机器负载均衡, 单机核心层, 单机引擎), 很遗憾, 由于业务所限, 一直没有看到这套系统能支持的量上限, 即使在峰值, 核心层qps大概也才50左右, 预计搜索量到千万级应该没什么压力, 当然, 优化的余地还很多.&lt;/p&gt;
&lt;p&gt;外面正在狂风骤雨, 开始吧&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="mu-biao"&gt;目标&lt;/h3&gt;
&lt;p&gt;当系统数据达到一定量时, 搜索就成为了除类目以外的第二大入口.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;更好的搜索结果(指标: 召回率, 转化率, 排序效果)&lt;/li&gt;
&lt;li&gt;更好的用户体验(下拉提示点击率,相关搜索准确率等)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="sou-suo-liu-cheng"&gt;搜索流程&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;用户在输入框输入关键词, 此时输入框会下拉提示一些词, 用户可以选择进行搜索&lt;/li&gt;
&lt;li&gt;用户点击, 进行搜索, 前端调用搜索接口&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;应用层&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;3 …&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">wklken</dc:creator><pubDate>Mon, 09 Jun 2014 00:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.wklken.me,2014-06-09:/posts/2014/06/09/search-system.html</guid><category>system</category></item></channel></rss>